{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.stats.diagnostic as diag\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "import sklearn.preprocessing\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.linear_model import Ridge\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "seed = random.seed(123)\n",
    "number_clusters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable classification\n",
    "train_data = pd.read_csv('./data/train.csv', encoding = \"ISO-8859-1\")\n",
    "test_data = pd.read_csv('./data/test.csv', encoding = \"ISO-8859-1\")\n",
    "variables = pd.read_csv('./data/variables.txt', encoding = \"ISO-8859-1\")\n",
    "quant_vars = list(variables.loc[(variables['Clasification'] == 'Cuantitativa')]['Variable'].values)\n",
    "quali_vars = list(variables.loc[(variables['Clasification'] == 'Cualitativa')]['Variable'].values)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando las variables numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[quant_vars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in quant_vars:\n",
    "    data = train_data[var].dropna(how='all', axis=0)\n",
    "    \n",
    "    # GrÃ¡fico\n",
    "    sns.displot(data, kde=True)\n",
    "\n",
    "    # Mostrando normalidad\n",
    "    print('\\033[1m' + var + '\\033[0m' + ': Kurtosis:', stats.kurtosis(data), 'Skewness:', stats.skew(data), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in quali_vars:\n",
    "  plt.figure(figsize=(20,5))\n",
    "  train_data[var].value_counts().plot(kind='bar')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la variable de interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print('Skewness: %f' % train_data['SalePrice'].skew())\n",
    "print('Kurtosis: %f' % train_data['SalePrice'].kurt())\n",
    "print('\\n---Describe---')\n",
    "train_data['SalePrice'].describe([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.65, 0.7, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat,p = stats.shapiro(train_data[[\"SalePrice\"]].dropna())\n",
    "print('Kolmogorov-Smirnov:\\np=%f\\n'% p)\n",
    "ks_statistic, p_value = diag.lilliefors(train_data[[\"SalePrice\"]].dropna())\n",
    "print('Lilliefors:\\nks=%f\\np=%f'%(ks_statistic,p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(train_data['SalePrice'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 #number of variables for heatmap\n",
    "corrmat = train_data.corr()\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train_data[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo la relacion entre las variables mas significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_data[cols],hue=\"SalePrice\")\n",
    "plt.show()\n",
    "# quant_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row): \n",
    "    if row['SalePrice'] > 0 and row['SalePrice'] <= 179280:\n",
    "        return 'Low'\n",
    "    elif row['SalePrice'] > 179280 and row['SalePrice'] < 326100:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Expensive'\n",
    "   \n",
    "train_data['SalesCategories'] = train_data.apply(lambda row: categorize(row), axis=1)\n",
    "\n",
    "\n",
    "print(train_data.groupby('SalesCategories').size().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_train_data = train_data.copy()\n",
    "copied_train_data = copied_train_data.fillna(0)\n",
    "\n",
    "\n",
    "y = copied_train_data.pop(\"SalesCategories\") #La variable respuesta\n",
    "X = copied_train_data[quant_vars] #El resto de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70% de entrenamiento y 30% prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X, y,test_size=0.3,train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train,y_train)\n",
    "y_pred = gaussian.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados esperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(y_pred)\n",
    "print('Low:', pred.count('Low'))\n",
    "print('Medium:', pred.count('Medium'))\n",
    "print('Expensive:', pred.count('Expensive'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = list(cm)\n",
    "labels = ['Exp', 'Low', 'Med']\n",
    "\n",
    "print('    '+labels[0]+'  '+labels[1]+'  '+labels[2])\n",
    "print(labels[0], cm[0][0], ' ',cm[0][1], '  ', cm[0][2])\n",
    "print(labels[1], cm[1][0], '  ',cm[1][1], '', cm[1][2])\n",
    "print(labels[2], cm[2][0], ' ',cm[2][1], ' ', cm[2][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suma por columna de la matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(labels[i], ':', sum(row[i] for row in cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print (\"Precision:\", precision_score(y_test,y_pred,average='micro') )\n",
    "print (\"Recall: \", recall_score(y_test,y_pred,average='micro'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33184972b48748d94ddd34e441bc25e543b9b1491b698e37ff4356c126c0090"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
